{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c971f385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available(), torch.cuda.is_bf16_supported()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178a33f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4a6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "head_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d37b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(seq_len, head_size).to(DEVICE)\n",
    "k = torch.randn(seq_len, head_size).to(DEVICE)\n",
    "v = torch.randn(seq_len, head_size).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acd9e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "M = 1024\n",
    "# Block col size\n",
    "B_c = M//(4 * head_size)\n",
    "B_r = min(M//(4 * head_size), head_size)\n",
    "\n",
    "O = torch.zeros(seq_len, head_size).to(DEVICE)\n",
    "l = torch.zeros(seq_len).to(DEVICE)\n",
    "m = torch.fill(torch.zeros(seq_len), float('-inf')).to(DEVICE)\n",
    "# mask = torch.tril(torch.ones(B_r, B_c)).to(DEVICE)\n",
    "parameters = [q, k, v]\n",
    "for i in parameters:\n",
    "    i.requires_grad_(True)\n",
    "\n",
    "# iterate over seqlen/B_c blocks of K and V\n",
    "T_c = seq_len // B_c\n",
    "T_r = seq_len // B_r\n",
    "for j in range(T_c):\n",
    "\n",
    "    # (B_c x head_size)\n",
    "    Kj = k[B_c * j:B_c * (j+1), :]\n",
    "    Vj = v[B_c * j:B_c * (j+1), :]\n",
    "\n",
    "    k_idx = torch.arange(B_c * j, B_c * (j + 1)).unsqueeze(0)\n",
    "\n",
    "    for i in range(T_r):\n",
    "        if i < j:\n",
    "            continue\n",
    "\n",
    "        # (B_r x head_size)\n",
    "        Qi = q[B_r * i:B_r * (i+1), :]\n",
    "        scale = 1.0 / sqrt(head_size)\n",
    "\n",
    "        # (B_r x head_size) @ (head_size x B_c)\n",
    "        # (B_r x B_c)\n",
    "        Sij = (Qi @ Kj.T) * scale\n",
    "\n",
    "        q_idx = torch.arange(B_r * i, B_r * (i + 1)).unsqueeze(1)\n",
    "        # B_r x B_c\n",
    "        mask = (q_idx >= k_idx).to(DEVICE)\n",
    "\n",
    "        # THE FUCKING BUG WAS HERE BUG BUG BUG FUCKKKKK\n",
    "        # here's a tip, heer. masked_fill is not in-place. masked_fill_ is\n",
    "        \n",
    "        Sij.masked_fill_(~mask, float('-inf'))\n",
    "        # (B_r)\n",
    "        mi_old = m[B_r * i : B_r * (i + 1)]\n",
    "\n",
    "        # (B_r)\n",
    "        li_old = l[B_r * i : B_r * (i + 1)]\n",
    "\n",
    "        # (B_r x head_size)\n",
    "        oi_old = O[B_r * i : B_r * (i + 1), :]\n",
    "\n",
    "        # torch max returns max of whole matrix if dim not specified.\n",
    "        # dim=1 searches for max across rows and along columns \n",
    "        # 0th index has the max values and 1st index has the indices of max values\n",
    "        # (B_r)\n",
    "        mij = torch.max(Sij,dim=1)[0]\n",
    "                \n",
    "        # (B_r x B_c) - (B_r) would be broadcasted to (B_r x B_r) and applied row wise\n",
    "        # unsqueeze(1) will make it (B_r x 1) and then it will be broadcasted column wise.\n",
    "        Pij = torch.exp(Sij - mij.unsqueeze(1))\n",
    "        lij = torch.sum(Pij, dim=1)\n",
    "\n",
    "        # stacked shape (2, B_r)\n",
    "        # max needs to be (B_r)\n",
    "        # reduce axis 0?\n",
    "        mi_new = torch.maximum(mi_old, mij)\n",
    "        \n",
    "        li_new = (torch.exp(mi_old - mi_new) * li_old + torch.exp(mij - mi_new) * lij)\n",
    "        # print(Sij.shape, Vj.shape)\n",
    "        # print(mi_old.shape)\n",
    "        # print(oi_old.shape)\n",
    "        # print(li_old.shape)\n",
    "        # print(torch.diag(li_old).shape)\n",
    "        # print(torch.exp(mi_old - mi_new).shape)\n",
    "        old_part = (oi_old * li_old.unsqueeze(1)) * torch.exp(mi_old - mi_new).unsqueeze(1)\n",
    "        # print(old_part.shape)\n",
    "        new_part = Pij @ Vj * (torch.exp(mij - mi_new).unsqueeze(1))\n",
    "        # print(new_part.shape)\n",
    "        # print(torch.diag(li_new).inverse())\n",
    "        Oi_new = ((old_part + new_part) / li_new.unsqueeze(1))\n",
    "        # print(Oi_new)\n",
    "        O[B_r * i : B_r * (i + 1), :] = Oi_new \n",
    "        m[B_r * i : B_r * (i + 1)] = mi_new\n",
    "        l[B_r * i : B_r * (i + 1)] = li_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a96a38",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62cb6e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8185, -0.5016,  2.4753,  ...,  0.6985,  0.3798, -0.5203],\n",
       "        [-0.6160, -0.6139,  1.2790,  ...,  0.4495,  0.2233, -0.2138],\n",
       "        [-0.4099, -0.9314,  0.3853,  ..., -0.1990, -0.8945,  0.0315],\n",
       "        ...,\n",
       "        [ 0.0433,  0.0072, -0.0419,  ...,  0.0544, -0.1109, -0.0151],\n",
       "        [ 0.0207,  0.0935, -0.0997,  ...,  0.0177, -0.1006,  0.0235],\n",
       "        [ 0.0280,  0.0298, -0.0399,  ...,  0.0534, -0.0121, -0.0324]],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa0062c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8185, -0.5016,  2.4753,  ...,  0.6985,  0.3798, -0.5203],\n",
       "        [-0.6160, -0.6139,  1.2790,  ...,  0.4495,  0.2233, -0.2138],\n",
       "        [-0.4099, -0.9314,  0.3853,  ..., -0.1990, -0.8945,  0.0315],\n",
       "        ...,\n",
       "        [ 0.0433,  0.0072, -0.0419,  ...,  0.0544, -0.1109, -0.0151],\n",
       "        [ 0.0207,  0.0935, -0.0997,  ...,  0.0177, -0.1006,  0.0235],\n",
       "        [ 0.0280,  0.0298, -0.0399,  ...,  0.0534, -0.0121, -0.0324]],\n",
       "       device='cuda:0', grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn = torch.nn.functional.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973bc5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-460083797.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mout_numel_is_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout_numel_is_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                     raise RuntimeError(\n\u001b[0m\u001b[1;32m    200\u001b[0m                         \u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "for i in parameters:\n",
    "    i.grad = None\n",
    "    O.backward()\n",
    "    print(v.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a700c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
