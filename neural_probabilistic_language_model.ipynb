{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp6h+wdwzovTPIfSDHcG2h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heerboi/AI-from-scratch/blob/main/neural_probabilistic_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: A Neural Probabilistic Language Model by Bengio et al. (Published Feb 2003!)\n",
        "\n",
        "Link: https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf"
      ],
      "metadata": {
        "id": "4u5YfQJB0AcG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm0yivL-z5OO",
        "outputId": "dfaeccb8-5e89-4614-80fe-917d156d9a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  222k  100  222k    0     0   797k      0 --:--:-- --:--:-- --:--:--  795k\n"
          ]
        }
      ],
      "source": [
        "!curl https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt > names.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(\"names.txt\", \"r\").read().splitlines()"
      ],
      "metadata": {
        "id": "iTNNnNhd0jXz"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ier-ZrZ40plE",
        "outputId": "75f42145-ef9b-4c59-f440-de327d746c75"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava']"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn"
      ],
      "metadata": {
        "id": "EknOlPdR0qUl"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars = [\".\"] + sorted(list(set(\"\".join(words))))"
      ],
      "metadata": {
        "id": "p_I-EtAs0zfe"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuwcSclQ0_oz",
        "outputId": "5c7af7f5-03ef-4e12-a37c-87d4db724324"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {s:i for i, s in enumerate(unique_chars)}\n",
        "itos = {i:s for s, i in stoi.items()}"
      ],
      "metadata": {
        "id": "EICJq9Xw4ChX"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = []\n",
        "ys = []\n",
        "block_size = 4\n",
        "for word in words:\n",
        "    word = word + \".\"\n",
        "\n",
        "    context = [0] * block_size\n",
        "\n",
        "    for char in word:\n",
        "        xs.append(context)\n",
        "        ys.append(stoi[char])\n",
        "        context = context[1:] + [stoi[char]]\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "51JnTGKI3qK2"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(xs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXV3KlFW4bNO",
        "outputId": "e8f0b20c-b10a-4de7-e59f-f4f377558c5e"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228146"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    xs, ys, test_size=0.10)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.50)"
      ],
      "metadata": {
        "id": "AayIS64l4qK1"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs[:5], ys[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a6zAeTT5Ozc",
        "outputId": "5b89c81b-a454-47be-9f11-60524cdd7a53"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  5],\n",
              "         [ 0,  0,  5, 13],\n",
              "         [ 0,  5, 13, 13],\n",
              "         [ 5, 13, 13,  1]]),\n",
              " tensor([ 5, 13, 13,  1,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. C -> embedding table of dims (unique words/tokens, embedding size)\n",
        "2. W1 -> weights for connections from input to hidden layer (input dim, hidden nodes)\n",
        "3. W2 -> weights for connections from hidden to output layer (hidden nodes, output dim)\n",
        "\n",
        "\n",
        "we makin a quadra-gram model, so three char embeddings as input. Input dims = 3 * embedding_size\n",
        "\n",
        "output dim is probabilities of next char, so it will be 27 (including dot to indicate end/start of name)"
      ],
      "metadata": {
        "id": "Yko8F2Re1GY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dims = 30\n",
        "hidden_size = 100\n",
        "learning_rate = 0.1\n",
        "unique_tokens = len(unique_chars)\n",
        "C = torch.nn.Embedding(num_embeddings=unique_tokens, embedding_dim=embedding_dims)\n",
        "\n",
        "W = torch.randn((block_size * embedding_dims, unique_tokens)) # (256, 20) x (20, 27) = (256, 27)\n",
        "H = torch.randn((block_size * embedding_dims, hidden_size))\n",
        "d = torch.randn(hidden_size)\n",
        "U = torch.randn((hidden_size, unique_tokens))\n",
        "b = torch.randn(unique_tokens)\n",
        "\n",
        "parameters = [C.weight, W, H, d, U, b]"
      ],
      "metadata": {
        "id": "GqOKQQ5k1AJm"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # Total trainable parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeirE4XkiLtg",
        "outputId": "69182c7c-f5e5-45b3-a4af-0bfed4a44da1"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18877"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "GWR7BK-IiTwi"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 200000\n",
        "batch_size = 512\n",
        "\n",
        "for iter in range(iterations):\n",
        "\n",
        "    # mini-batch\n",
        "    ix = torch.randint(0, X_train.shape[0], (batch_size,))\n",
        "\n",
        "\n",
        "    # fw pass\n",
        "    # (examples, embeds * 3) * (embeds * 3, hidden)\n",
        "    # (examples, hidden) * (hidden, unique_tokens)\n",
        "\n",
        "    # X_train_embeds = (batch_size, block_size * embedding_size)\n",
        "    X_train_embeds = C(X_train[ix]).view(-1, block_size * embedding_dims)\n",
        "    assert(X_train_embeds.shape[0] == batch_size)\n",
        "\n",
        "    # Tanh(Hx + d)\n",
        "    HxD = torch.tanh(X_train_embeds @ H + d)\n",
        "\n",
        "    # U(W1X) + b\n",
        "    U_d = HxD @ U + b\n",
        "\n",
        "    Wx = X_train_embeds @ W\n",
        "\n",
        "    outputs = Wx + U_d\n",
        "\n",
        "    # bw pass\n",
        "    # loss = -outputs[torch.arange(X_train.shape[0]), y_train].log().mean()\n",
        "    loss = F.cross_entropy(outputs, y_train[ix])\n",
        "\n",
        "    # C.weight.grad = None\n",
        "    # W1.grad = None\n",
        "    # W2.grad = None\n",
        "    for p in parameters:\n",
        "        p.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    #     X_val_embeds = C(X_val).view(-1, block_size * embedding_dims)\n",
        "    #     W1X = torch.tanh(X_val_embeds @ W1)\n",
        "    #     W2W1 = W1X @ W2\n",
        "    #     # outputs = F.softmax(W2W1, dim = 1)\n",
        "    #     # val_loss = -outputs[torch.arange(X_val.shape[0]), y_val].log().mean()\n",
        "    #     val_loss = F.cross_entropy(W2W1, y_val)\n",
        "\n",
        "    if iter > 100000:\n",
        "        learning_rate = 0.01\n",
        "\n",
        "\n",
        "    # C.weight.data -= learning_rate * C.weight.grad\n",
        "    # W1.data -= learning_rate * W1.grad\n",
        "    # W2.data -= learning_rate * W2.grad\n",
        "    for p in parameters:\n",
        "        p.data -= learning_rate * p.grad\n",
        "\n",
        "    if iter % 10000 == 0:\n",
        "        print(f\"{iter} | Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymFhyXyr5bHT",
        "outputId": "01d7a0dc-09e5-4a3e-c344-f168c90f6493"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 | Loss: 31.76503562927246\n",
            "10000 | Loss: 2.1501147747039795\n",
            "20000 | Loss: 2.1738152503967285\n",
            "30000 | Loss: 2.253756046295166\n",
            "40000 | Loss: 2.1920087337493896\n",
            "50000 | Loss: 2.178954839706421\n",
            "60000 | Loss: 2.0707366466522217\n",
            "70000 | Loss: 1.9934029579162598\n",
            "80000 | Loss: 2.053574323654175\n",
            "90000 | Loss: 2.212862491607666\n",
            "100000 | Loss: 1.9982186555862427\n",
            "110000 | Loss: 2.1132164001464844\n",
            "120000 | Loss: 2.08832049369812\n",
            "130000 | Loss: 2.1042370796203613\n",
            "140000 | Loss: 2.1109704971313477\n",
            "150000 | Loss: 2.0421621799468994\n",
            "160000 | Loss: 2.1163203716278076\n",
            "170000 | Loss: 2.091182231903076\n",
            "180000 | Loss: 2.045867919921875\n",
            "190000 | Loss: 1.9896823167800903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing testing\n",
        "with torch.no_grad():\n",
        "    X_test_embeds = C(X_test).view(-1, block_size * embedding_dims)\n",
        "\n",
        "    HxD = torch.tanh(X_test_embeds @ H + d)\n",
        "\n",
        "    # U(W1X) + b\n",
        "    U_d = HxD @ U + b\n",
        "\n",
        "    Wx = X_test_embeds @ W\n",
        "\n",
        "    outputs = Wx + U_d\n",
        "\n",
        "    # outputs = F.softmax(W2W1, dim = 1)\n",
        "    # loss = -outputs[torch.arange(X_test.shape[0]), y_test].log().mean()\n",
        "    loss = F.cross_entropy(outputs, y_test)\n",
        "\n",
        "    print(f\"Test loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG7wgHbuLrHN",
        "outputId": "99b3b5d8-49e9-4d32-917f-dfd55e8302c5"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 2.150269031524658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names = []\n",
        "for _ in range(5):\n",
        "    new_name = \".\" * block_size\n",
        "    while True:\n",
        "        with torch.no_grad():\n",
        "            input = torch.tensor([stoi[i] for i in new_name[-block_size:]])\n",
        "            input_embeds = C(input).view(-1, block_size * embedding_dims)\n",
        "\n",
        "            HxD = torch.tanh(input_embeds @ H + d)\n",
        "\n",
        "            U_d = HxD @ U + b\n",
        "\n",
        "            Wx = input_embeds @ W\n",
        "\n",
        "            outputs = F.softmax(Wx + U_d, dim = 1)\n",
        "\n",
        "            next_pred = itos[torch.multinomial(outputs, num_samples = 1, replacement = True).item()]\n",
        "\n",
        "            if next_pred == \".\":\n",
        "                names.append(new_name[block_size:])\n",
        "                break\n",
        "            new_name += next_pred\n",
        "\n",
        "names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lCFZFV7_lbg",
        "outputId": "ce7024f1-a333-44d7-96c9-6ed1110e55c7"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['keianna', 'zavary', 'alieah', 'tyvisenna', 'krizley']"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I BEAT ANDREJ KARPATHY's MODEL WOOOOOOO"
      ],
      "metadata": {
        "id": "_fsUSuhI-x5u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QR4epMjB6U-"
      },
      "execution_count": 140,
      "outputs": []
    }
  ]
}