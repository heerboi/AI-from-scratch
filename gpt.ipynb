{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyON68D0Hq1V3+giQJ9ks4Ho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heerboi/AI-from-scratch/blob/main/gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following Andrej's video: https://www.youtube.com/watch?v=kCc8FmEb1nY"
      ],
      "metadata": {
        "id": "NytWV_Vpyx2s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkpGHe1_yuQ4",
        "outputId": "7f89f2fb-921e-4685-fdf2-01d7e60b58c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-29 09:58:14--  https://raw.githubusercontent.com/karpathy/char-rnn/refs/heads/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-07-29 09:58:15 (24.3 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/refs/heads/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding=\"utf-8\") as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "qbTGZmhxzsE4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "N43VhIWwzy7q",
        "outputId": "b06f3d36-c773-4854-e23b-468df5d8ca3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dwInOXkzzs5",
        "outputId": "6e03b721-cb6b-4d3d-bfca-b275b8ee1d22"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {s:i for i,s in enumerate(chars)}\n",
        "itos = {i:s for s, i in stoi.items()}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: \"\".join([itos[i] for i in l])\n",
        "\n",
        "print(encode(\"Hii\"))\n",
        "print(decode(encode(\"Hii\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00b0b11Oz7Ck",
        "outputId": "b50aa765-a269-4aea-9179-e139bb76d32d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20, 47, 47]\n",
            "Hii\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aZlOpG90XO8",
        "outputId": "d3517b62-070b-42c9-b950-8fe3d5436760"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(0.9*len(data))\n",
        "train_data = data[:split]\n",
        "val_data = data[split:]\n",
        "print(len(train_data))\n",
        "print(len(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoNIpIhf04Lu",
        "outputId": "cbf4b8a1-135c-44ed-e15f-298276fde03f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1003854\n",
            "111540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#context length\n",
        "\n",
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiXWgSi01F8t",
        "outputId": "4d0a0753-0fcd-4888-e68a-97d3d9cbdc46"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(context, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOj5UHbN1Y9v",
        "outputId": "a5789bc6-b467-4fb0-d918-fcd48c374944"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([18]) tensor(47)\n",
            "tensor([18, 47]) tensor(56)\n",
            "tensor([18, 47, 56]) tensor(57)\n",
            "tensor([18, 47, 56, 57]) tensor(58)\n",
            "tensor([18, 47, 56, 57, 58]) tensor(1)\n",
            "tensor([18, 47, 56, 57, 58,  1]) tensor(15)\n",
            "tensor([18, 47, 56, 57, 58,  1, 15]) tensor(47)\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47]) tensor(58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
        "\n",
        "    return x, y\n",
        "\n",
        "x, y = get_batch(\"train\")\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "tM64g1Zr1vpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32962e37-1a39-48b2-df6e-cea4b96c4c22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(num_embeddings = vocab_size, embedding_dim = vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        logits = self.token_embedding_table(idx)\n",
        "\n",
        "        if targets == None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(-1)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self(idx)\n",
        "            # last time step for each batch and include all embeddings\n",
        "            logits = logits[:, -1, :]\n",
        "\n",
        "            probabilities = F.softmax(logits, dim=1)\n",
        "            # (B, 1)\n",
        "            next_idx = torch.multinomial(probabilities, num_samples=1)\n",
        "            # (B, T+1)\n",
        "            idx = torch.cat((idx, next_idx), dim=1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "out, loss = m(x, y)\n",
        "print(out.shape)\n",
        "print(out)\n",
        "\n",
        "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4M6EPHBoMlu",
        "outputId": "2f5af3b0-bc7a-4da5-9ee1-b92f004c8dea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor([[ 0.5818,  0.4265, -0.0615,  ..., -0.0789, -0.3012, -1.6240],\n",
            "        [ 0.3451,  0.4943, -0.3435,  ...,  0.1659, -0.9840, -0.0468],\n",
            "        [-0.7417, -1.0830, -0.7216,  ...,  0.1426,  0.2233,  0.4919],\n",
            "        ...,\n",
            "        [-1.5073, -0.5039,  1.2100,  ...,  1.3121,  0.2871, -0.4249],\n",
            "        [-0.1006,  1.9914, -0.1507,  ..., -1.9687, -0.8738, -1.5913],\n",
            "        [ 0.9281,  0.7552, -0.6514,  ..., -1.1617,  0.3738, -0.6385]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "\n",
            "p\n",
            "R:?!T,OAjIZqMheATXkO Y,kMzT'wpgwkxzUltuG-:X;PRyM:Ryu?eU\n",
            "E'yrsx'KfkCO$Dx'3UM..FB:RTaQjd\n",
            "lhF.AHrq!ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "3qsOfqfxo86l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "for steps in range(5000):\n",
        "    xb,yb = get_batch('train')\n",
        "\n",
        "    logits, loss = m(xb,yb)\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K2DOnUlrDg0",
        "outputId": "522aca35-179d-4f02-9980-10e51709df47"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.417945384979248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=1000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMxS4jlAuH80",
        "outputId": "7ad5265f-6a5b-4d20-aa24-9378421f2b58"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Win s,-ve woni&,\n",
            "I mabu pleanginf-f herouthen e,\n",
            "AHe.\n",
            "Awily als yode, te me'Therethare,\n",
            "MI V:\n",
            "Orothed.\n",
            "Se almin hy Larearay, urig torighe bs te m spre y ain cils hras my soneo.\n",
            "\n",
            "Thre gedrthemuritha'dwo d timmenghe thatin them; wofe, t l, l t hin bor ly nd t, gu icu pe tr d t hertom e isp,\n",
            "\n",
            "YTyowarom oras apit thet mel th helou oru, lld; fitowise!3!\n",
            "'sen, bee s bl haknore?\n",
            "S qDYod llifo? pu chedDUE:\n",
            "F:\n",
            "TETCLENos me ver hardeastellerpe asthice Oufas! res bat uce t suere withat veated d y s.\n",
            "THas rdon, tlo, cin tixge soorwosndo s ma hath eais th.\n",
            "OMyorslGLKIVod e st ben g wrd beit f s t m!\n",
            "A:\n",
            "AMzwn taicead at yo ar fodlthat r;\n",
            "hil ft poree moyowot.\n",
            "CHat'lan-m sake, LO:\n",
            "\n",
            "swilofathe howe\n",
            "TEDUKARl t r beyo I I Imif mp-\n",
            "O: wiee t r f s'ds it\n",
            "ARmureathir:\n",
            "TE: tris if spll ert hepe th targhosutie rde, s theathapth f h isULIO:\n",
            "t wesuth brst\n",
            "Kn ons aday nt ste he, d tin\n",
            "R:\n",
            "BEd k s che y ar hey'the kn tres, her udinnd waingo3\n",
            "NUSoumounQjanonsormof owhoris w!\n",
            "Se llliso mean ow,\n",
            "And fref, tesar nen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_iters = 200\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    m.eval()\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            xb, yb = get_batch(split)\n",
        "            logits, loss = m(xb, yb)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    m.train()\n",
        "    return out\n",
        "estimate_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWurTw1mujpA",
        "outputId": "e38c4ab8-5150-47cd-e77e-4acdde59cb33"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': tensor(2.4848), 'val': tensor(2.4994)}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mathematical trick in self-attention!\n",
        "\n",
        "- have to average the logits in the time dim 0..t for logit t\n"
      ],
      "metadata": {
        "id": "ON796oN7wS5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B, T, C = 4, 8, 2\n",
        "x = torch.randn(B,T,C)"
      ],
      "metadata": {
        "id": "_dUS8nJvvWiK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "div"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfFUBnbBxgT3",
        "outputId": "5ea7c0be-6003-437c-8132-e9050085825d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "div = torch.tril(torch.ones(T,T))\n",
        "div /= div.sum(dim=1, keepdim=True)\n",
        "xbow = div @ x"
      ],
      "metadata": {
        "id": "qPtTXEaowgzX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "div"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_xjzMN0wyTa",
        "outputId": "1bee9033-db7f-4aa8-a649-b5a966732897"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0], xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPV5L8ePxMF4",
        "outputId": "ebb3f475-2627-4b2a-dfcb-f7b4be0e5402"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.8146,  0.1880],\n",
              "         [-0.2609,  1.2275],\n",
              "         [-0.5190, -0.2259],\n",
              "         [-0.0393, -0.3051],\n",
              "         [ 1.0878, -0.0201],\n",
              "         [ 0.8852,  0.2780],\n",
              "         [ 0.2748, -0.4538],\n",
              "         [-0.8744, -0.2523]]),\n",
              " tensor([[-0.8146,  0.1880],\n",
              "         [-0.5378,  0.7078],\n",
              "         [-0.5315,  0.3966],\n",
              "         [-0.4085,  0.2211],\n",
              "         [-0.1092,  0.1729],\n",
              "         [ 0.0565,  0.1904],\n",
              "         [ 0.0877,  0.0984],\n",
              "         [-0.0326,  0.0545]]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### using softmax(infinity)\n",
        "\n",
        "hint: e^-infinity = 0, and e^0 = 1"
      ],
      "metadata": {
        "id": "YXm70ToFyUmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T, T))\n",
        "wei = wei.masked_fill(tril==0, float('-inf'))\n",
        "wei = F.softmax(wei,dim=1)\n",
        "xbow3 = wei @ x\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35Sr49cCx0zp",
        "outputId": "6fd146d2-d1df-4cfb-81f3-9a36a12bd159"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eq5w5Pgyyxr9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}