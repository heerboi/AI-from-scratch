{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFluerGj1yjykEUTp4gSUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heerboi/AI-from-scratch/blob/main/neural_probabilistic_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: A Neural Probabilistic Language Model by Bengio et al. (Published Feb 2003!)\n",
        "\n",
        "Link: https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf"
      ],
      "metadata": {
        "id": "4u5YfQJB0AcG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm0yivL-z5OO",
        "outputId": "8ced3a1e-3160-41a9-ae04-1d6d18877d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  222k  100  222k    0     0   233k      0 --:--:-- --:--:-- --:--:--  233k\n"
          ]
        }
      ],
      "source": [
        "!curl https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt > names.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(\"names.txt\", \"r\").read().splitlines()"
      ],
      "metadata": {
        "id": "iTNNnNhd0jXz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ier-ZrZ40plE",
        "outputId": "5cd81fc6-b878-47a9-eec2-e03494b571df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn"
      ],
      "metadata": {
        "id": "EknOlPdR0qUl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars = [\".\"] + sorted(list(set(\"\".join(words))))"
      ],
      "metadata": {
        "id": "p_I-EtAs0zfe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuwcSclQ0_oz",
        "outputId": "db2c5f90-1804-4e82-c2fb-837c74740333"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {s:i for i, s in enumerate(unique_chars)}\n",
        "itos = {i:s for s, i in stoi.items()}"
      ],
      "metadata": {
        "id": "EICJq9Xw4ChX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for word in words:\n",
        "    word = word + \".\"\n",
        "\n",
        "    context = [\".\", \".\", \".\"]\n",
        "\n",
        "    for char in word:\n",
        "        xs.append([stoi[i] for i in context])\n",
        "\n",
        "        ys.append(stoi[char])\n",
        "        context = context[1:] + [char]\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "51JnTGKI3qK2"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(xs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXV3KlFW4bNO",
        "outputId": "abede242-2039-49b6-8c98-df8ea7a18fe9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228146"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    xs, ys, test_size=0.20)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.428)"
      ],
      "metadata": {
        "id": "AayIS64l4qK1"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a6zAeTT5Ozc",
        "outputId": "cbe3841d-da23-46f3-d132-58db3fad0449"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5, 25,  1],\n",
              "        [14,  4, 15],\n",
              "        [ 1, 22,  9],\n",
              "        [13,  9, 15],\n",
              "        [ 0,  3, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. C -> embedding table of dims (unique words/tokens, embedding size)\n",
        "2. W1 -> weights for connections from input to hidden layer (input dim, hidden nodes)\n",
        "3. W2 -> weights for connections from hidden to output layer (hidden nodes, output dim)\n",
        "\n",
        "\n",
        "we makin a quadra-gram model, so three char embeddings as input. Input dims = 3 * embedding_size\n",
        "\n",
        "output dim is probabilities of next char, so it will be 27 (including dot to indicate end/start of name)"
      ],
      "metadata": {
        "id": "Yko8F2Re1GY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dims = 5\n",
        "hidden_size = 15\n",
        "learning_rate = 1\n",
        "unique_tokens = len(unique_chars)\n",
        "C = torch.nn.Embedding(num_embeddings=unique_tokens, embedding_dim=embedding_dims)\n",
        "\n",
        "W1 = torch.randn((3 * embedding_dims, hidden_size), requires_grad=True)\n",
        "W2 = torch.randn((hidden_size, unique_tokens), requires_grad=True)"
      ],
      "metadata": {
        "id": "GqOKQQ5k1AJm"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 2000\n",
        "\n",
        "for iter in range(iterations):\n",
        "\n",
        "    # fw pass\n",
        "    # (examples, embeds * 3) * (embeds * 3, hidden)\n",
        "    # (examples, hidden) * (hidden, unique_tokens)\n",
        "\n",
        "    X_train_embeds = C(X_train).view(-1, 3 * embedding_dims)\n",
        "\n",
        "    W1X = torch.tanh(X_train_embeds @ W1)\n",
        "    W2W1 = W1X @ W2\n",
        "\n",
        "    # w2w1 = (examples, unique_tokens)\n",
        "    # have to add up the COLUMNS and take softmax!\n",
        "    # dim = 1 (sum along dim 1)\n",
        "    outputs = F.softmax(W2W1, dim=1)\n",
        "\n",
        "\n",
        "    # bw pass\n",
        "    loss = -outputs[torch.arange(X_train.shape[0]), y_train].log().mean()\n",
        "\n",
        "    C.weight.grad = None\n",
        "    W1.grad = None\n",
        "    W2.grad = None\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        X_val_embeds = C(X_val).view(-1, 3 * embedding_dims)\n",
        "        W1X = torch.tanh(X_val_embeds @ W1)\n",
        "        W2W1 = W1X @ W2\n",
        "        outputs = F.softmax(W2W1, dim = 1)\n",
        "        val_loss = -outputs[torch.arange(X_val.shape[0]), y_val].log().mean()\n",
        "\n",
        "\n",
        "    C.weight.data -= learning_rate * C.weight.grad\n",
        "    W1.data -= learning_rate * W1.grad\n",
        "    W2.data -= learning_rate * W2.grad\n",
        "\n",
        "    if iter % 100 == 0:\n",
        "        print(f\"{iter + 1} | Loss: {loss.item()} | Validation loss: {val_loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymFhyXyr5bHT",
        "outputId": "a7a426e8-b4fd-4e3b-83b8-a6f3dc18b5e7"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 | Loss: 2.3431262969970703 | Validation loss: 2.3545219898223877\n",
            "101 | Loss: 2.3404242992401123 | Validation loss: 2.351945161819458\n",
            "201 | Loss: 2.3379321098327637 | Validation loss: 2.3495779037475586\n",
            "301 | Loss: 2.335564136505127 | Validation loss: 2.3473286628723145\n",
            "401 | Loss: 2.333195924758911 | Validation loss: 2.3450636863708496\n",
            "501 | Loss: 2.33221173286438 | Validation loss: 2.3441758155822754\n",
            "601 | Loss: 2.328718423843384 | Validation loss: 2.340710163116455\n",
            "701 | Loss: 2.326855421066284 | Validation loss: 2.3389840126037598\n",
            "801 | Loss: 2.3253426551818848 | Validation loss: 2.337675094604492\n",
            "901 | Loss: 2.323465347290039 | Validation loss: 2.336019515991211\n",
            "1001 | Loss: 2.3221242427825928 | Validation loss: 2.334901809692383\n",
            "1101 | Loss: 2.3201677799224854 | Validation loss: 2.3330795764923096\n",
            "1201 | Loss: 2.3198046684265137 | Validation loss: 2.3329594135284424\n",
            "1301 | Loss: 2.318779945373535 | Validation loss: 2.3320841789245605\n",
            "1401 | Loss: 2.3178024291992188 | Validation loss: 2.3312318325042725\n",
            "1501 | Loss: 2.316887378692627 | Validation loss: 2.3304286003112793\n",
            "1601 | Loss: 2.3160221576690674 | Validation loss: 2.329664468765259\n",
            "1701 | Loss: 2.3151943683624268 | Validation loss: 2.3289265632629395\n",
            "1801 | Loss: 2.31439208984375 | Validation loss: 2.3282039165496826\n",
            "1901 | Loss: 2.313610792160034 | Validation loss: 2.3274953365325928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing testing\n",
        "with torch.no_grad():\n",
        "    X_test_embeds = C(X_test).view(-1, 3 * embedding_dims)\n",
        "\n",
        "    W1X = torch.tanh(X_test_embeds @ W1)\n",
        "    W2W1 = W1X @ W2\n",
        "\n",
        "    outputs = F.softmax(W2W1, dim = 1)\n",
        "    loss = -outputs[torch.arange(X_test.shape[0]), y_test].log().mean()\n",
        "\n",
        "    print(f\"Test loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG7wgHbuLrHN",
        "outputId": "5a57929c-d9d0-47e4-a328-3060b8f637b0"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 2.323338747024536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names = []\n",
        "for _ in range(5):\n",
        "    new_name = \"...\"\n",
        "    while True:\n",
        "        with torch.no_grad():\n",
        "            input = torch.tensor([stoi[i] for i in new_name[-3:]])\n",
        "            input_embeds = C(input).view(-1, 3 * embedding_dims)\n",
        "\n",
        "            W1X = torch.tanh(input_embeds @ W1)\n",
        "            W2W1 = W1X @ W2\n",
        "            outputs = F.softmax(W2W1, dim=1)\n",
        "\n",
        "            next_pred = itos[torch.multinomial(outputs, num_samples = 1, replacement = True).item()]\n",
        "\n",
        "            if next_pred == \".\":\n",
        "                names.append(new_name[3:])\n",
        "                break\n",
        "            new_name += next_pred\n",
        "\n",
        "names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lCFZFV7_lbg",
        "outputId": "96a17856-3abe-4b8b-9c48-f27ac31267ae"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dixan', 'leyon', 'vyn', 'ches', 'mamylonenee']"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QR4epMjB6U-"
      },
      "execution_count": 125,
      "outputs": []
    }
  ]
}